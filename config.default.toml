[general]
# The directory to search for new audio files
input_dir = "/data/input"
# The managed output directory where audio files and new files will live
store_dir = "/data/store"
# The minimal record length in seconds to process an audio file. 0 = disabled
min_length_seconds = 5.0
# Remove audio files that are shorter than min_length_seconds
remove_short_files = true
# Remove successfully processed audio files after this delay. The date is either the file modification date or the bundle date, whichever is later. 0 = disabled
delete_source_audio_after_days = 0

[text]
# Whether to generate summaries from transcripts
summary_enabled = true
# Base URL for the local OpenAI-compatible API.
#   Example for openwebui: http://localhost:8080/api
#api_base_url = "http://localhost:8080/api"
# Key as required by your API (or any dummy text if value not needed), will be passed using Bearer auth
#api_key = "your_api_key_here"
# Example: mistral-medium-latest
#model = "mistral-medium-latest"
# (Optional) Extra context to provide to the AI when summarizing audio content, beside the basic instruction.
#extra_context = null

[audio]
# Example for speaches: http://localhost:8000/v1
#api_base_url = "http://localhost:8000/v1"
# Key as required by your API (or any dummy text if value not needed), will be passed using Bearer auth
#api_key = "your_api_key_here"
# Model to use for transcription. Must support streaming.
# Example: Kelno/whisper-large-v3-french-distil-dec16-ct2
#model = "Kelno/whisper-large-v3-french-distil-dec16-ct2"
# Whether to use streaming transcription
#stream = true
